{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "sam_class.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dajiro-repo/blog/blob/master/sam_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9c1km-eg5Va",
        "outputId": "370a27cb-b545-48bb-c68c-6bf173e8a183"
      },
      "source": [
        "!git clone https://github.com/davda54/sam.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'sam'...\n",
            "remote: Enumerating objects: 116, done.\u001b[K\n",
            "remote: Counting objects: 100% (116/116), done.\u001b[K\n",
            "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
            "remote: Total 116 (delta 48), reused 47 (delta 16), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (116/116), 634.08 KiB | 5.51 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dz2aCf4Ig-XH",
        "outputId": "787553b3-90d0-46df-c1eb-3acc5e1e34f2"
      },
      "source": [
        "!curl -LO https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\r\n",
        "!tar -xzvf cifar-10-python.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  162M  100  162M    0     0  43.5M      0  0:00:03  0:00:03 --:--:-- 43.5M\n",
            "cifar-10-batches-py/\n",
            "cifar-10-batches-py/data_batch_4\n",
            "cifar-10-batches-py/readme.html\n",
            "cifar-10-batches-py/test_batch\n",
            "cifar-10-batches-py/data_batch_3\n",
            "cifar-10-batches-py/batches.meta\n",
            "cifar-10-batches-py/data_batch_2\n",
            "cifar-10-batches-py/data_batch_5\n",
            "cifar-10-batches-py/data_batch_1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCQtR7cfgv9x"
      },
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from typing import Any, Callable, Optional, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils as utils\n",
        "import torchvision\n",
        "import torchvision.utils as vutils\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "\n",
        "from sam.sam import SAM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2Ld9vY6gv95"
      },
      "source": [
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='latin1')\n",
        "    return dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JALcLR1Wgv95"
      },
      "source": [
        "###############\n",
        "# 入力パラメータ\n",
        "###############\n",
        "#バッチサイズ\n",
        "batch_size = 32\n",
        "#エポック数\n",
        "epochs = 50\n",
        "#GPUID\n",
        "ngpu = 1\n",
        "#学習率\n",
        "lr = 0.001\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9T1_57f8gv96"
      },
      "source": [
        "def get_data_loaders(batch_size):\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    \n",
        "    train_data = CIFAR10(train=True, transform=transform)\n",
        "    test_data = CIFAR10(train=False, transform=transform)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "                                             shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n",
        "                                             shuffle=True)\n",
        "    \n",
        "    return train_loader, test_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vny_oyIXgv96"
      },
      "source": [
        "class CIFAR10():\n",
        "    train_list = [\n",
        "        \"cifar-10-batches-py/data_batch_1\",\n",
        "        \"cifar-10-batches-py/data_batch_2\",\n",
        "        \"cifar-10-batches-py/data_batch_3\",\n",
        "        \"cifar-10-batches-py/data_batch_4\",\n",
        "        \"cifar-10-batches-py/data_batch_5\",\n",
        "    ]\n",
        "    test_list = [\n",
        "        \"cifar-10-batches-py/test_batch\"\n",
        "    ]\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        train: bool =True,\n",
        "        transform: Optional[Callable] = None\n",
        "    ) -> None:\n",
        "        self.transform = transform\n",
        "        self.train = train\n",
        "        if self.train:\n",
        "            data_list = self.train_list\n",
        "        else:\n",
        "            data_list = self.test_list\n",
        "        \n",
        "        self.data: Any = []\n",
        "        self.targets = []\n",
        "        \n",
        "        for filename in data_list:\n",
        "            entry = unpickle(filename)\n",
        "            self.data.append(entry[\"data\"])\n",
        "            self.targets.extend(entry[\"labels\"])\n",
        "        \n",
        "        self.data = np.vstack(self.data).reshape(-1, 3, 32, 32)\n",
        "        self.data = self.data.transpose(0, 2, 3, 1)\n",
        "        \n",
        "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
        "        img, target = self.data[index], self.targets[index]\n",
        "        \n",
        "        img = Image.fromarray(img)\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        \n",
        "        return img, target \n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_JEncdRgv96"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuE2N8zzgv97"
      },
      "source": [
        "model = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "base_optimizer = optim.SGD\n",
        "optimizer = SAM(model.parameters(), base_optimizer, lr = lr, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wJi205DE0tG"
      },
      "source": [
        "# model = Net()\r\n",
        "# criterion = nn.CrossEntropyLoss()\r\n",
        "# base_optimizer = optim.Adam\r\n",
        "# optimizer = SAM(model.parameters(), base_optimizer, lr = lr)\r\n",
        "# model = Net()\r\n",
        "# criterion = nn.CrossEntropyLoss()\r\n",
        "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UODZ7LOzgv97"
      },
      "source": [
        "dataloaders_dict = {}\n",
        "train_loader, test_loader = get_data_loaders(batch_size)\n",
        "dataloaders_dict[\"train\"] = train_loader\n",
        "dataloaders_dict[\"test\"] = test_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPMeNUg7gv97"
      },
      "source": [
        "accuracy, accuracy_val = [], []\n",
        "model.to(device)\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    for phase in [\"train\", \"test\"]:\n",
        "        if phase == \"train\":\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()\n",
        "\n",
        "        loss_epoch = 0.0\n",
        "        acc_epoch = 0.0\n",
        "\n",
        "        if (epoch == 0) and (phase == \"train\"):\n",
        "            continue\n",
        "\n",
        "        for inputs, labels in dataloaders_dict[phase]:\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            with torch.set_grad_enabled(phase == \"train\"):\n",
        "                labels = labels.to(device)\n",
        "                inputs = inputs.to(device)\n",
        "                outputs = model(inputs)\n",
        "                \n",
        "                loss = criterion(outputs, labels)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                \n",
        "                if phase == \"train\":\n",
        "                    # fisrt forward-backward pass\n",
        "                    loss.backward()\n",
        "                    optimizer.first_step(zero_grad=True)\n",
        "                    \n",
        "                    # second forward-backward pass\n",
        "                    criterion(model(inputs), labels).backward()\n",
        "                    optimizer.second_step(zero_grad=True)\n",
        "                    \n",
        "                loss_epoch += loss.item() * inputs.size(0)\n",
        "                acc_epoch += torch.sum(preds == labels.data)\n",
        "        \n",
        "        loss_epoch = loss_epoch / len(dataloaders_dict[phase].dataset)\n",
        "        acc_epoch = acc_epoch.double() / len(dataloaders_dict[phase].dataset)\n",
        "        print(f\"phase: {phase}\",\n",
        "              f\"epoch: {epoch}\",\n",
        "              f\"loss: {loss_epoch:.4f}\",\n",
        "              f\"accuracy: {acc_epoch:.4f}\")\n",
        "             # f\"accuracy: {acc_epoch}:.4f}\")\n",
        "            \n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}